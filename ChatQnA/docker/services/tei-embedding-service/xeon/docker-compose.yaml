services:
  tei-embedding-service:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.2
    container_name: tei-embedding-server
    ports:
      - "6006:80"
    volumes:
      - "./data:/data"
    shm_size: 1g
    environment:
      no_proxy: ${no_proxy}
      http_proxy: ${http_proxy}
      https_proxy: ${https_proxy}
    command: --model-id ${EMBEDDING_MODEL_ID} --auto-truncate
